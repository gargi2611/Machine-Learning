{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308f123d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee4996",
   "metadata": {},
   "source": [
    "A simple logistic regression (with gradient descent) model working on a dataset of 4298563 instances.\n",
    "The model gave an accuracy of 63.5% - training and 68.37% - testing with iterations = 500 and learning rate = 0.05.\n",
    "Similar results obtained for all possible combinations of iterations = 100 and learning rate = 0.1.\n",
    "The model proves to be underfitting for our dataset due to being too simple for the data\n",
    "(inference from similar values for training and test accuracies, Jtrain & jtest - similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ecc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "data = pd.read_csv('data.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebcfbe1",
   "metadata": {},
   "source": [
    "VECTOR SHAPES\n",
    "X = n x m\n",
    "Y = 1 x m\n",
    "w = n x 1\n",
    "Z = 1 x m\n",
    "A = 1 x m\n",
    "m: the number of datasets\n",
    "n: the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0578b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing-2\n",
    "train_set_X = data.iloc[:4000000, :-1].values.transpose()\n",
    "train_set_Y = data.iloc[:4000000, 61].values.reshape(1,train_set_X.shape[1])\n",
    "test_set_X = data.iloc[4000000: , :-1].values.transpose()\n",
    "test_set_Y = data.iloc[4000000:, 61].values.reshape(1,test_set_X.shape[1])\n",
    "print(test_set_X.shape)\n",
    "print(test_set_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb718801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function: sigmoid\n",
    "def sigmoid(z):\n",
    "  return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "#helper function: parameter initialization\n",
    "def initialize(dim):\n",
    "    \"\"\" intializes vector w of shape(dim,1) and b as 0 \"\"\"\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    return w, b  \n",
    "\n",
    "#helper function: forward & back propagation\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "   \n",
    "    #FORWARD\n",
    "    Z = np.dot(w.transpose(), X) + b\n",
    "    #print(Z.shape)\n",
    "    A = sigmoid(Z)\n",
    "    #print(A.shape)\n",
    "    cost = -(np.dot(Y, np.log(A).transpose())+ np.dot((1-Y), np.log(1-A).transpose()))\n",
    "   \n",
    "    #BACKWARD\n",
    "    dZ = A - Y\n",
    "    dw = np.dot(X, dZ.transpose())/m\n",
    "    db = np.sum(dZ)/m\n",
    "   \n",
    "    gradients = {\"dw\" : dw,\n",
    "                 \"db\" : db}\n",
    "    return gradients, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ffd1fa",
   "metadata": {},
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function: optimize via Gradient Descent\n",
    "def gradientDescent(w, b ,X, Y, iterations, alpha, print_cost):\n",
    "    costs  = []\n",
    "    for i in range(iterations):\n",
    "       \n",
    "        #forward & back propagation\n",
    "        grads, cost = propagate(w, b ,X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "       \n",
    "        #weight updation\n",
    "        w = w - alpha*dw\n",
    "        b = b - alpha*db\n",
    "       \n",
    "        if (i%100) == 0:\n",
    "            costs.append(cost)\n",
    "           \n",
    "        if print_cost and (i%100==0):\n",
    "            print(\"the cost after \"+ str(i) +\" iterations is: \"+ str(cost))\n",
    "           \n",
    "    params = {\"w\" : w,\n",
    "              \"b\" : b}\n",
    "    grads = {\"dw\" : dw,\n",
    "             \"db\" : db}\n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecca8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function: to predict new values\n",
    "def predict(w, b, X):\n",
    "    \"\"\" w is a (n x 1) matrix, X is a (m x n) matrix \"\"\"\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)  #no idea why this exist?\n",
    "   \n",
    "    Z = np.dot(w.transpose(), X)+b\n",
    "    A = sigmoid(Z)\n",
    "   \n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0][i]<=0.5:\n",
    "            Y_prediction[0][i] = 0\n",
    "        else:\n",
    "            Y_prediction[0][i] = 1\n",
    "   \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "def model(X_train, Y_train, X_test, Y_test, iterations, alpha, print_cost):\n",
    "   \n",
    "    #initialize\n",
    "    w, b = initialize(X_train.shape[0])\n",
    "   \n",
    "    #fw & bp\n",
    "    params, grads, costs = gradientDescent(w, b, X_train, Y_train, iterations, alpha, print_cost)\n",
    "   \n",
    "    #retreive parameters\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "   \n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "   \n",
    "    #print accuracies\n",
    "   # print(Y_prediction_train.shape)\n",
    "    #print(Y_train.shape)\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "   \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test,\n",
    "         \"Y_prediction_train\" : Y_prediction_train,\n",
    "         \"w\" : w,\n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : alpha,\n",
    "         \"iterations\": iterations}\n",
    "   \n",
    "    return d\n",
    "\n",
    "d = model(train_set_X, train_set_Y, test_set_X, test_set_Y, iterations = 500, alpha = 0.05, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041380e3",
   "metadata": {},
   "source": [
    "OUTPUT :    the cost after 0 iterations is: [[2772588.72223999]]\n",
    "            the cost after 100 iterations is: [[2636107.19196553]]\n",
    "            the cost after 200 iterations is: [[2624253.75377114]]\n",
    "            the cost after 300 iterations is: [[2623146.61367674]]\n",
    "            the cost after 400 iterations is: [[2623040.22673616]]\n",
    "            train accuracy: 63.58705 %\n",
    "            test accuracy: 68.30719144703127 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb486c4",
   "metadata": {},
   "source": [
    "# #Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3815bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized version time : 583.6904048919678ms\n",
      "non-vectorized version time: 348.9847183227539ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time as time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "print(\"vectorized version time : \"+ str(1000* (toc-tic))+ \"ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c+= a[i]*b[i]\n",
    "   \n",
    "toc = time.time()\n",
    "print(\"non-vectorized version time: \"+ str(1000* (toc-tic))+ \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e6f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
